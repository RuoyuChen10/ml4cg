# -*- coding: utf-8 -*-
"""autoencoder.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1d6YxGSnEN1xr82Yo6AMio3RXMIkV6DX3
"""

__author__ = 'Alexander Koenig and Li Nguyen'

"""Imports"""

import argparse
import os
import random
import torch
import torch.nn as nn
import torch.nn.parallel
import torch.backends.cudnn as cudnn
import torch.optim as optim
import torch.utils.data
import torchvision.datasets as dset
import torchvision.transforms as transforms
import torchvision.utils as vutils
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation
#from IPython.display import HTML

"""Next, we initialize some parameters for our auto encoder that should avoid redundance of hard-coded elements."""

# Root directory for dataset
dataroot = "/home/dcor/ronmokady/workshop20/celebA"

# Number of workers for dataloader (half as batch size)
workers = 64

# Batch size during training (assignment says has to be bigger than 2)
batch_size = 128

# assignment requires an image size of 128x128: resize images to this size using a transformer
image_size = 128

# Number of channels: RGB
nc = 3

# Size of latent vector z, given in assignment as 256
nz = 256

# Size of feature maps in encoder (number featuremaps encoder)
nfe = 128

# Size of feature maps in decoder (number featuremaps decoder)
nfd = 128

# Number of training epochs
num_epochs = 5

# Learning rate for optimizers
lr = 0.0002

# Beta1 hyperparameter for Adam optimizer (adam optimizer is a requirement of the assignment)
beta1 = 0.5

# Number of GPUs available. Use 0 for CPU mode.
ngpu = 0

"""In the following step we initialize our dataset.
The images are loaded from the specified dataroot in the celeba folder on the same level. 
We resize the images to have a resolution of 128x128 and crop from the center. We perform normalization with mean and standard deviation for 3 channels.
"""

dataset = dset.ImageFolder(root=dataroot,
                           transform=transforms.Compose([
                               transforms.Resize(image_size),
                               transforms.CenterCrop(image_size),
                               transforms.ToTensor(),
                               # given mean, and std deviation for 3 channels. We transform them to Tensors of normalized range [-1, 1]
                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
                           ]))

# Create the dataloader
dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,
                                         shuffle=True, num_workers=workers)

# Decide which device we want to run on
device = torch.device("cuda:0" if (torch.cuda.is_available() and ngpu > 0) else "cpu")

"""Next, we visualize some data"""

# Plot some training images
real_batch = next(iter(dataloader))
plt.figure(figsize=(8,8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))

"""Below, we define the architecture of our auto encoder.
For the encoding layers we choose the ReLU function and for the decoding layers with deconvolutions we choose the Leaky ReLU function. The layers are built by a convolution, batch normalization and the activation.
"""

class Autoencoder(nn.Module):
    def __init__(self):
        super(Autoencoder, self).__init__()
        self.ngpu = ngpu
        self.encoder = nn.Sequential(
            
            # Layer 1 
            nn.Conv2d(3, 64, kernel_size=4, stride = 1, padding = 0, bias=False), # 3 input channels for RGB images
            nn.BatchNorm2d(64),
            nn.ReLU(True),

            # Layer 2
            nn.Conv2d(64, nfe, kernel_size=4, stride = 1, padding = 0, bias=False),
            nn.BatchNorm2d(nfe),
            nn.ReLU(True),

            # Layer 3
            nn.Conv2d(64, nfe, kernel_size=4, stride = 1, padding = 0, bias=False),
            nn.BatchNorm2d(nfe*2),
            nn.ReLU(True),

            # Layer 4
            nn.Conv2d(nfe, nfe*4, kernel_size=4, stride=1, padding=0, bias=False),
            nn.BatchNorm2d(nfd*4),
            nn.ReLU(True),

            # Layer 5
            nn.Conv2d(nfe, nfe * 8, kernel_size=4, stride=1, padding=0, bias=False),
            nn.BatchNorm2d(nfe*8),
            nn.ReLU(True),

            # Layer 6: convert this thing to a latent vector z (flattened has to be of size 256)
            nn.Conv2d(nfe * 8, nz, kernel_size=4, stride = 1, padding = 0, bias=False),
            nn.ReLU(True))

        self.decoder = nn.Sequential(             
            # Layer 1
            nn.ConvTranspose2d(nz, nfd * 8, 4, 1, 0, bias=False),
            nn.BatchNorm2d(nfd * 8), # number of features
            nn.LeakyReLU(True), # params: in_place: bool

            # Layer 2: size of cuboid is (nfd*8) x 4 x 4
            nn.ConvTranspose2d(nfd * 8, nfd * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(nfd * 4),
            nn.LeakyReLU(True),

            # Layer 3: size of cuboid is (ngf*4) x 8 x 8
            nn.ConvTranspose2d(nfd * 4, nfd * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(nfd * 2),
            nn.LeakyReLU(True),

            # Layer 4: size of cuboid is (ngf*2) x 16 x 16
            nn.ConvTranspose2d(nfd * 2, nfd, 4, 2, 1, bias=False),
            nn.BatchNorm2d(nfd),
            nn.LeakyReLU(True),

            # Layer 5: size of cuboid is (ngf) x 32 x 32
            nn.ConvTranspose2d(nfd, 64, 4, 2, 1, bias=False),
            nn.BatchNorm2d(64),
            nn.LeakyReLU(True),

            # Layer 6
            nn.ConvTranspose2d(64, nc, 4, 2, 1, bias=False),
            # The output of the decoder is fed through a tanh function to return it to the input data range of [-1,1]
            nn.Tanh())
            # size: (nc) x 128 x 128
            
    def forward(self,x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x

# weight initialization randomly initializing from a normal distribution
def weights_init(m):
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        # params: tensor, mean and std, fill the input tensor with values drawn from the standard distribution with given mean and std
        nn.init.normal_(m.weight.data, 0.0, 0.02)
    elif classname.find('BatchNorm') != -1:
        nn.init.normal_(m.weight.data, 1.0, 0.02)
        # for batch norm also initializing the bias (The weight and bias in BatchNorm are the gamma and beta 
        # in the documentation, while gamma is the root of the variance, and beta is the expectation)
        nn.init.constant_(m.bias.data, 0)

# Instantiating the autoencoder
# Check out the printed model to see the autoencoder object's architecture

# Create the autoencoder
autoencoder = Autoencoder()

# Print the model
print(autoencoder)

# Apply the weights_init function to randomly initialize all weights to mean=0, stdev=0.2.
autoencoder.apply(weights_init)

# Initialize MSELoss function (L2 loss because assignment requires either L1 or L2 loss)
criterion = nn.MSELoss()

# Setup an Adam optimizer
optimizer = optim.Adam(autoencoder.parameters(), lr=lr, betas=(beta1, 0.999))

"""Now it's time to train our network!"""

print("Starting Training Loop...")

# For each epoch
for epoch in range(num_epochs):
    # For each batch in the dataloader
    for i, data in enumerate(dataloader, 0):
        
        # format batch
        real_cpu = data[0].to(device)
        b_size = real_cpu.size(0)

        # the labels are in our case the real images: How far are our generated images away from the original ones
        img, _ = data
        img = Variable(img)

        # forward pass
        output = autoencoder(real_cpu)
        loss = criterion(output, img)

        # backward pass
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        print('epoch [{}/{}], loss:{:.4f}'
          .format(epoch+1, num_epochs, loss.data[0]))
        if epoch % 10 == 0:
            pic = to_img(output.cpu().data)
            save_image(pic, './dc_img/image_{}.png'.format(epoch))
